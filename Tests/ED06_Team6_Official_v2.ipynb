{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba2909df",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c8e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fuzzywuzzy import process #https://github.com/seatgeek/fuzzywuzzy\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import  GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a27f8d",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19662bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_brand_name (df, col, brand_list):\n",
    "    \"\"\"\n",
    "    Correcting the brand names of the cars that are not spelled correctly\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Dataframe\n",
    "        The dataframe of the data\n",
    "    col : String\n",
    "        The name of the column that we want to correct\n",
    "    brand_list : List\n",
    "        List of the correct names of the brands\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : Dataframe\n",
    "        The main dataframe with the names spelled correctly\n",
    "\n",
    "    \"\"\"\n",
    "    for brand in brand_list:\n",
    "        matches = process.extract(brand, df[col], limit = df.shape[0])\n",
    "        for potential_match in matches: \n",
    "            if potential_match[1]>70:\n",
    "                df.loc[df['brand_name']==potential_match[0], col]=brand\n",
    "                \n",
    "    return df\n",
    "\n",
    "def encode_string (df, list_with_features, encoder):\n",
    "    \"\"\"\n",
    "    Encode the string columns to transform them to numerical\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Dataframe\n",
    "        The dataframe\n",
    "    col : String\n",
    "        Name of the feature to encode\n",
    "    encoder : Class, Encoder\n",
    "        Name of the encoder that we will use\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : Dataframe\n",
    "        The dataframe with the feature encoded\n",
    "\n",
    "    \"\"\"\n",
    "    for feature in list_with_features:\n",
    "        df[f'encoded_{feature}'] = encoder.fit_transform(df[feature])\n",
    "    return df\n",
    "\n",
    "def fill_na(df, imputer):\n",
    "    \"\"\"\n",
    "    Filling the NaN values of the dataframe with an imputer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Dataframe\n",
    "        The main dataframe\n",
    "    imputer : Class (KNNImputer)\n",
    "        The imputer we will use\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : Dataframe\n",
    "        The dataframe with no NaN values\n",
    "\n",
    "    \"\"\"\n",
    "    features = df.drop(columns=['encoded_brand_name', 'car name']).columns.tolist()\n",
    "    array = imputer.fit_transform(df[features])\n",
    "    df = pd.DataFrame(array, columns=features)\n",
    "    return df\n",
    "\n",
    "def drop_outliers(df, feature, threshold):\n",
    "    \"\"\"\n",
    "    Function to drop the outliers \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Dataframe\n",
    "        The main Dataframe\n",
    "    cols_with_outliers : List\n",
    "        List with the features that have outliers\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : Dataframe\n",
    "        The main dataframe without the outliers\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df = df[~(df[feature]>= df[feature].quantile(0.75) + threshold*(df[feature].quantile(0.75)-df[feature].quantile(0.25)))]\n",
    "    return df\n",
    "\n",
    "def train_predict(model, X_train, X_test, Y_train, Y_test):\n",
    "    \"\"\"\n",
    "    Predict on train and test set so that we can optimize the model after\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Model : Class (GradientBoostingRegressor)\n",
    "        The regressor we will use to predict the target\n",
    "    X_train : 2D numpy array\n",
    "        Values of the features of the train set\n",
    "    X_test : 2D numpy array\n",
    "        Values of the features of the test set\n",
    "    Y_train : 1D numpy array\n",
    "        The target values of the train set \n",
    "    Y_test : 1D numpy array\n",
    "        The target values of the test set to compare the predictions\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Printing the accuracy of the model on train and test set predictions\n",
    "\n",
    "    \"\"\"\n",
    "    model.fit(X_train, Y_train)\n",
    "    predict_train = model.predict(X_train)\n",
    "    predict_test = model.predict(X_test)\n",
    "    print(f'Train and predict using: {model}')\n",
    "    print(f'The root mean squared error on the train set is: {np.sqrt(mean_squared_error(Y_train, predict_train))}')\n",
    "    print(f'The root mean squared error on the test set is: {np.sqrt(mean_squared_error(Y_test, predict_test))}')\n",
    "    print(f'The mean absolute error on train set is: {mean_absolute_error(Y_train, predict_train)}')\n",
    "    print(f'The mean absolute error on test set is: {mean_absolute_error(Y_test, predict_test)}')\n",
    "    print(f'The R2 accuracy on train set is: {r2_score(Y_train, predict_train)}')\n",
    "    print(f'The R2 accuracy on test set is: {r2_score(Y_test, predict_test)}')\n",
    "\n",
    "def sanity_check (X_train, Y_train, X_test, Y_test):\n",
    "    \"\"\"\n",
    "    Checking the shapes of the train and test sets \n",
    "    Input:\n",
    "        All the sets we need\n",
    "    Output:\n",
    "        Printing the shapes to check that everything is great\n",
    "    \"\"\"\n",
    "    print ('Shape of X_train=>',X_train.shape)\n",
    "    print ('Shape of X_test=>',X_test.shape)\n",
    "    print ('Shape of Y_train=>',Y_train.shape)\n",
    "    print ('Shape of Y_test=>',Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a85163",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e61b330",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91f5d58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "path = 'C:/Users/Maverick/Documents/Development/Regeneration/Project/Data/mpg.data.xlsx'\n",
    "df = pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4097f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns that are not useful\n",
    "df=df.drop(['Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8342831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpg               True\n",
      "cylinders        False\n",
      "displacements    False\n",
      "horsepower        True\n",
      "weight           False\n",
      "acceleration     False\n",
      "model year       False\n",
      "origin           False\n",
      "car name         False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Checking for NaN values in the dataframe\n",
    "df.columns = ['mpg',\t'cylinders',\t'displacements', \t'horsepower',\t'weight',\t'acceleration',\t'model year',\t'origin',\t'car name']\n",
    "print(df.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6c16bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating the brand name from the car name\n",
    "df['brand_name'] = df['car name'].str.split(\" \").str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0045448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the brand names\n",
    "brand_list = ['chevrolet', 'mazda', 'mercedes-benz', 'toyota', 'vw']\n",
    "df = correct_brand_name(df, 'brand_name', brand_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ee5994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode string feature to numerical ones\n",
    "list_of_features_to_encode = ['cylinders', 'origin', 'brand_name', 'model year']\n",
    "df = encode_string(df, list_of_features_to_encode, LabelEncoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8111152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping the string feature that we encoded\n",
    "drop = ['cylinders', 'origin', 'brand_name', 'model year']\n",
    "df.drop(columns=drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "316c18b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NaN values with the KNNImputer\n",
    "df = fill_na(df, KNNImputer(n_neighbors=2, weights='uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23742ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From EDA we know there are outliers in acceleration and in horsepower\n",
    "# We create a dataframe with no outliers\n",
    "df = drop_outliers(df, 'horsepower', 1.8)\n",
    "df = drop_outliers(df, 'acceleration', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe64b65",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "458d47fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data to train and test sets with target the MPG\n",
    "seed = 21\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.drop('mpg', axis=1), df['mpg'], test_size=0.2, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9177d677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train=> (322, 7)\n",
      "Shape of X_test=> (81, 7)\n",
      "Shape of Y_train=> (322,)\n",
      "Shape of Y_test=> (81,)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check of the arrays' shapes\n",
    "sanity_check(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc5c2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the imput data with standardscaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2d4112a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and predict using: GradientBoostingRegressor()\n",
      "The root mean squared error on the train set is: 1.359596997389613\n",
      "The root mean squared error on the test set is: 2.0953893155085828\n",
      "The mean absolute error on train set is: 1.0504774508948949\n",
      "The mean absolute error on test set is: 1.619263056210526\n",
      "The R2 accuracy on train set is: 0.969870195401348\n",
      "The R2 accuracy on test set is: 0.9242876751396395\n"
     ]
    }
   ],
   "source": [
    "# Training the model on train set and predicting the target on test set\n",
    "train_predict(GradientBoostingRegressor(), X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best parameters for the model with grid search\n",
    "search_grid = {'n_estimators':[500,1000,2000], \n",
    "               'learning_rate':[.001,0.01,.1], \n",
    "               'max_depth':[1,2,4], \n",
    "               'subsample':[.5,.75,1], \n",
    "               'random_state':[1]}\n",
    "gsv = GridSearchCV(estimator=GradientBoostingRegressor(), param_grid=search_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "gsv.fit(X_train, Y_train)\n",
    "print(f'The best score from the grid search is: {gsv.best_score_}')\n",
    "print(f'The best parameters from the grid search is: {gsv.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f34acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimimal parameters for the model to train and predict\n",
    "model = GradientBoostingRegressor(learning_rate=0.01, max_depth=2, n_estimators=1000, random_state=1, subsample=0.5)\n",
    "train_predict(model, X_train, X_test, Y_train, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
