{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d7ddea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23e197c8",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0fb464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from fuzzywuzzy import process #package to correct misspelling labels\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, Normalizer, MaxAbsScaler, RobustScaler, QuantileTransformer, PowerTransformer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor, StackingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, train_test_split, RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.impute import SimpleImputer, KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c96776d",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e59f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_brand_name (df, col, brand_list):\n",
    "    \"\"\"\n",
    "    Correcting the brand names of the cars that are not spelled correctly\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Dataframe\n",
    "        The dataframe of the data\n",
    "    col : String\n",
    "        The name of the column that we want to correct\n",
    "    brand_list : List\n",
    "        List of the correct names of the brands\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : Dataframe\n",
    "        The main dataframe with the names spelled correctly\n",
    "\n",
    "    \"\"\"\n",
    "    for brand in brand_list:\n",
    "        matches = process.extract(brand, df[col], limit = df.shape[0])\n",
    "        for potential_match in matches: \n",
    "            if potential_match[1]>70:\n",
    "                df.loc[df['brand_name']==potential_match[0], col]=brand\n",
    "                \n",
    "    return df\n",
    "\n",
    "def encode_string (df, list_with_features, encoder):\n",
    "    \"\"\"\n",
    "    Encode the string columns to transform them to numerical\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Dataframe\n",
    "        The dataframe\n",
    "    col : String\n",
    "        Name of the feature to encode\n",
    "    encoder : Class, Encoder\n",
    "        Name of the encoder that we will use\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : Dataframe\n",
    "        The dataframe with the feature encoded\n",
    "\n",
    "    \"\"\"\n",
    "    for feature in list_with_features:\n",
    "        df[f'encoded_{feature}'] = encoder.fit_transform(df[feature])\n",
    "    return df\n",
    "\n",
    "def fill_na(df, imputer):\n",
    "    \"\"\"\n",
    "    Filling the NaN values of the dataframe with an imputer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Dataframe\n",
    "        The main dataframe\n",
    "    imputer : Class (KNNImputer)\n",
    "        The imputer we will use\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : Dataframe\n",
    "        The dataframe with no NaN values\n",
    "\n",
    "    \"\"\"\n",
    "    features = df.drop(columns=['encoded_brand_name', 'car name']).columns.tolist()\n",
    "    array = imputer.fit_transform(df[features])\n",
    "    df = pd.DataFrame(array, columns=features)\n",
    "    return df\n",
    "\n",
    "def drop_outliers(df, feature, threshold):\n",
    "    \"\"\"\n",
    "    Function to drop the outliers \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Dataframe\n",
    "        The main Dataframe\n",
    "    cols_with_outliers : List\n",
    "        List with the features that have outliers\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : Dataframe\n",
    "        The main dataframe without the outliers\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df = df[~(df[feature]>= df[feature].quantile(0.75) + threshold*(df[feature].quantile(0.75)-df[feature].quantile(0.25)))]\n",
    "    return df\n",
    "\n",
    "def train_predict(model, X_train, X_test, Y_train, Y_test):\n",
    "    \"\"\"\n",
    "    Predict on train and test set so that we can optimize the model after\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Model : Class (GradientBoostingRegressor)\n",
    "        The regressor we will use to predict the target\n",
    "    X_train : 2D numpy array\n",
    "        Values of the features of the train set\n",
    "    X_test : 2D numpy array\n",
    "        Values of the features of the test set\n",
    "    Y_train : 1D numpy array\n",
    "        The target values of the train set \n",
    "    Y_test : 1D numpy array\n",
    "        The target values of the test set to compare the predictions\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Printing the accuracy of the model on train and test set predictions\n",
    "\n",
    "    \"\"\"\n",
    "    model.fit(X_train, Y_train)\n",
    "    predict_train = model.predict(X_train)\n",
    "    predict_test = model.predict(X_test)\n",
    "    print(f'Train and predict using: {model}')\n",
    "    print(f'The root mean squared error on the train set is: {np.sqrt(mean_squared_error(Y_train, predict_train))}')\n",
    "    print(f'The root mean squared error on the test set is: {np.sqrt(mean_squared_error(Y_test, predict_test))}')\n",
    "    print(f'The mean absolute error on train set is: {mean_absolute_error(Y_train, predict_train)}')\n",
    "    print(f'The mean absolute error on test set is: {mean_absolute_error(Y_test, predict_test)}')\n",
    "    print(f'The R2 accuracy on train set is: {r2_score(Y_train, predict_train)}')\n",
    "    print(f'The R2 accuracy on test set is: {r2_score(Y_test, predict_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b177abf",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed735f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "path = 'C:/Users/Maverick/Documents/Development/Regeneration/Project/Data/mpg.data.xlsx'\n",
    "df = pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e4b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns that are not usefull\n",
    "df=df.drop(['Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67f600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for NaN values in the dataframe\n",
    "df.columns = ['mpg',\t'cylinders',\t'displacements', \t'horsepower',\t'weight',\t'acceleration',\t'model year',\t'origin',\t'car name']\n",
    "print(f\"{df.describe()}\\n\")\n",
    "print(f'{df.info()}\\n')\n",
    "print(df.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6dd937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating the brand name from the car name\n",
    "df['brand_name'] = df['car name'].str.split(\" \").str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb89cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the brand names\n",
    "brand_list = ['chevrolet', 'mazda', 'mercedes-benz', 'toyota', 'vw']\n",
    "df = correct_brand_name(df, 'brand_name', brand_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d47088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode string feature to numerical ones\n",
    "list_of_features_to_encode = ['origin', 'brand_name', 'model year']\n",
    "df = encode_string(df, list_of_features_to_encode, LabelEncoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038549f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping the string feature that we encoded\n",
    "drop = ['origin', 'brand_name', 'model year']\n",
    "df.drop(columns=drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19803d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NaN values with the KNNImputer\n",
    "df = fill_na(df, KNNImputer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dd054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From EDA we know there are outliers in acceleration and in horsepower\n",
    "# We create a dataframe with no outliers\n",
    "df = drop_outliers(df, 'horsepower', 1.8)\n",
    "df = drop_outliers(df, 'acceleration', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9c8145",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df)\n",
    "# Splitting the data to train and test sets with target the MPG\n",
    "seed = 21\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.drop('mpg', axis=1), df['mpg'], test_size=0.2, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfcf815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the imput data with standardscaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce5f858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model on train set and predicting the target on test set\n",
    "train_predict(GradientBoostingRegressor(), X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0113084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best parameters for the model with grid search\n",
    "search_grid = {'n_estimators':[500,1000,2000], \n",
    "               'learning_rate':[.001,0.01,.1], \n",
    "               'max_depth':[1,2,4], \n",
    "               'subsample':[.5,.75,1], \n",
    "               'random_state':[1]}\n",
    "gsv = GridSearchCV(estimator=GradientBoostingRegressor(), param_grid=search_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "gsv.fit(X_train, Y_train)\n",
    "print(f'The best score from the grid search is: {gsv.best_score_}')\n",
    "print(f'The best parameters from the grid search is: {gsv.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f85b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the best parameters on the model to train and predict\n",
    "model = GradientBoostingRegressor(learning_rate=0.01, max_depth=2, n_estimators=1000, random_state=1, subsample=0.5)\n",
    "train_predict(model, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e60349f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e4ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f972d804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc18802b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49937838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a97df3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7862eab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac37d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b1273e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0865e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
